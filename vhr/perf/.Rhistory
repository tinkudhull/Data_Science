install_tensorflow(gpu=TRUE)
library(keras)
install_tensorflow(gpu=TRUE)
install.packages("tensorflow")
install.packages("tensorflow")
library(tensorflow)
library(keras)
library(tensorflow)
library(tensorflow)
install_tensorflow(gpu = TRUE)
#loading keras library
library(keras)
#loading the keras inbuilt mnist dataset
data<-dataset_mnist()
data<-dataset_mnist()
library(keras)
library(devtools)
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
system("g++ -v")
system("where make")
?compile_dll
?compiler_flags
R-package/src/install.libs.R
R-package/src/install.libs
package/src/install.libs
devtools::install_github("Microsoft/LightGBM@v1", subdir = "R-package")
library(lightgbm)
install.packages("mxnet")
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
library(mxnet)
?mx.model.FeedForward.create
?mx.symbol.Pooling
train<-read.csv('https://github.com/ozt-ca/tjo.hatenablog.samples/raw/master/r_samples/public_lib/jp/mnist_reproduced/short_prac_train.csv')
train<-read.csv('https://github.com/ozt-ca/tjo.hatenablog.samples/raw/master/r_samples/public_lib/jp/mnist_reproduced/short_prac_train.csv')
test<-read.csv('https://github.com/ozt-ca/tjo.hatenablog.samples/raw/master/r_samples/public_lib/jp/mnist_reproduced/short_prac_test.csv')
library(Matrix)
train<-data.matrix(train)
test<-data.matrix(test)
train.x<-train[,-1]
train.y<-train[,1]
train.x<-t(train.x/255)
test_org<-test
test<-test[,-1]
test<-t(test/255)
table(train.y)
data <- mx.symbol.Variable('data')
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",
+                            kernel=c(2,2), stride=c(2,2))
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",kernel=c(2,2), stride=c(2,2))
conv2 <- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",kernel=c(2,2), stride=c(2,2))
flatten <- mx.symbol.Flatten(data=pool2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
data <- mx.symbol.Variable("data")
devices<-mx.cpu()
# first conv
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1,p=0.5)
# second conv
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2,p=0.5)
# first fullc
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh4 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop4 <- mx.symbol.Dropout(data=tanh4,p=0.5)
# second fullc
fc2 <- mx.symbol.FullyConnected(data=drop4, num_hidden=10)
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
model <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
ctx=devices, num.round=60, array.batch.size=100,
learning.rate=0.05, momentum=0.9, wd=0.00001,
eval.metric=mx.metric.accuracy,
epoch.end.callback=mx.callback.log.train.metric(100))
print(proc.time() - tic)
preds <- predict(model, test.array)
pred.label <- max.col(t(preds)) - 1
table(test_org[,1],pred.label)
table(test_org[,1],pred.label)
head(pred)
head(preds)
preds <- predict(model, test.array)
preds
preds
head(train)
save.image("~/Files/cnnw.RData")
load("~/Files/cnnw.RData")
summary(model)
preds <- predict(model, test.array)
preds <- predict(model, test.array)
model
head(train)
table(train.y)
data <- mx.symbol.Variable("data")
devices<-mx.cpu()
# first conv
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1,p=0.5)
# second conv
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2,p=0.5)
# third conv
conv3 <- mx.symbol.Convolution(data=drop2, kernel=c(5,5), num_filter=80)
tanh3 <- mx.symbol.Activation(data=conv3, act_type="relu")
pool3 <- mx.symbol.Pooling(data=tanh3, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop3 <- mx.symbol.Dropout(data=pool2,p=0.5)
# first fullc
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh4 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop4 <- mx.symbol.Dropout(data=tanh4,p=0.5)
# second fullc
fc2 <- mx.symbol.FullyConnected(data=drop4, num_hidden=10)
#loss
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
tic <- proc.time()
model <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
ctx=devices, num.round=60, array.batch.size=100,
learning.rate=0.05, momentum=0.9, wd=0.00001,
eval.metric=mx.metric.accuracy,
epoch.end.callback=mx.callback.log.train.metric(100))
print(proc.time()  - tic)
library(mxnet)
data <- mx.symbol.Variable("data")
devices<-mx.cpu()
# first conv
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1,p=0.5)
# second conv
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2,p=0.5)
# third conv
conv3 <- mx.symbol.Convolution(data=drop2, kernel=c(5,5), num_filter=80)
tanh3 <- mx.symbol.Activation(data=conv3, act_type="relu")
pool3 <- mx.symbol.Pooling(data=tanh3, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop3 <- mx.symbol.Dropout(data=pool2,p=0.5)
# first fullc
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh4 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop4 <- mx.symbol.Dropout(data=tanh4,p=0.5)
# second fullc
fc2 <- mx.symbol.FullyConnected(data=drop4, num_hidden=10)
#loss
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
tic <- proc.time()
model <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
ctx=devices, num.round=60, array.batch.size=100,
learning.rate=0.05, momentum=0.9, wd=0.00001,
eval.metric=mx.metric.accuracy,
epoch.end.callback=mx.callback.log.train.metric(100))
print(proc.time()  - tic)
preds <- predict(model, test.array)
head(preds)
pred.label <- max.col(t(preds)) - 1
table(test_org[,1],pred.label)
sum(diag(table(test_org[,1],pred.label)))/1000
summary(model)
data <- mx.symbol.Variable("data")
devices<-mx.cpu()
# first conv
conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
tanh1 <- mx.symbol.Activation(data=conv1, act_type="relu")
pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop1 <- mx.symbol.Dropout(data=pool1,p=0.5)
# second conv
conv2 <- mx.symbol.Convolution(data=drop1, kernel=c(5,5), num_filter=50)
tanh2 <- mx.symbol.Activation(data=conv2, act_type="relu")
pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop2 <- mx.symbol.Dropout(data=pool2,p=0.5)
# third conv
conv3 <- mx.symbol.Convolution(data=drop2, kernel=c(3,3), num_filter=80)
tanh3 <- mx.symbol.Activation(data=conv3, act_type="relu")
pool3 <- mx.symbol.Pooling(data=tanh3, pool_type="max",kernel=c(2,2), stride=c(2,2))
drop3 <- mx.symbol.Dropout(data=pool2,p=0.5)
# first fullc
flatten <- mx.symbol.Flatten(data=drop2)
fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
tanh4 <- mx.symbol.Activation(data=fc1, act_type="relu")
drop4 <- mx.symbol.Dropout(data=tanh4,p=0.5)
# second fullc
fc2 <- mx.symbol.FullyConnected(data=drop4, num_hidden=10)
#loss
lenet <- mx.symbol.SoftmaxOutput(data=fc2)
train.array <- train.x
dim(train.array) <- c(28, 28, 1, ncol(train.x))
test.array <- test
dim(test.array) <- c(28, 28, 1, ncol(test))
mx.set.seed(0)
tic <- proc.time()
model <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
ctx=devices, num.round=60, array.batch.size=100,
learning.rate=0.05, momentum=0.9, wd=0.00001,
eval.metric=mx.metric.accuracy,
epoch.end.callback=mx.callback.log.train.metric(100))
print(proc.time()  - tic)
preds <- predict(model, test.array)
pred.label <- max.col(t(preds)) - 1
table(test_org[,1],pred.label)
sum(diag(table(test_org[,1],pred.label)))/1000
install.packages("prob")
library(lightgbm)
data(agaricus.train, package='lightgbm')
train <- agaricus.train
str(train)
str(train)
dtrain <- lgb.Dataset(train$data, label=train$label)
params <- list(objective="regression", metric="l2")
model <- lgb.cv(params, dtrain, 10, nfold=5, min_data=1, learning_rate=1, early_stopping_rounds=10)
data(agaricus.test, package='lightgbm')
data(agaricus.train, package = "lightgbm")
data(agaricus.test, package = "lightgbm")
dtrain <- lgb.Dataset(agaricus.train$data, label = agaricus.train$label)
dtest <- lgb.Dataset(agaricus.test$data, label = agaricus.test$label)
valids <- list(eval = dtest, train = dtrain)
print("Start running example to start from a initial prediction")
?lgb.train
??lgb.train
library(lightgbm)
predict(model, dtest)
install.packages("R6")
install.packages("R6")
install.packages("R6")
install.packages("R6")
install.packages("R6")
library(R6)
library(lightgbm)
data(iris)
str(iris)
iris$Species <- as.numeric(as.factor(iris$Species)) - 1
str(iris)
table(iris$Species)
train <- as.matrix(iris[c(1:40, 51:90, 101:140), ])
test <- as.matrix(iris[c(41:50, 91:100, 141:150), ])
dtrain <- lgb.Dataset(data = train[, 1:4], label = train[, 5])
dtest <- lgb.Dataset.create.valid(dtrain, data = test[, 1:4], label = test[, 5])
valids <- list(test = dtest)
params <- list(objective = "multiclass", metric = "multi_error", num_class = 3)
model <- lgb.train(params,
dtrain,
100,
valids,
min_data = 1,
learning_rate = 1,
early_stopping_rounds = 10)
my_preds <- predict(model, test[, 1:4])
my_preds
model <- lgb.train(list(),
dtrain,
100,
valids,
min_data = 1,
learning_rate = 1,
early_stopping_rounds = 10,
objective = "multiclass",
metric = "multi_error",
num_class = 3)
my_preds <- predict(model, test[, 1:4])
my_preds
my_preds <- predict(model, test[, 1:4], reshape = TRUE)
my_preds
predict(model, test[, 1:4], rawscore = TRUE)
predict(model, test[, 1:4], rawscore = TRUE, reshape = TRUE)
predict(model, test[, 1:4], predleaf = TRUE)
predict(model, test[, 1:4], predleaf = TRUE, reshape = TRUE)
?lightgbm::lgb.cv
?lightgbm::lgb.cv()
lightgbm::lgb.cv()
lightgbm::lgb.cv
library(prob)
S <- rolldie(2, makespace = TRUE)
S
A <- subset(S, X1 + X2 >= 8)
B <- subset(S, X1 == 3) #Given
Prob(A, given = B)
x <- rnorm(1000, 99.2, 1.2)
x
x <- rnorm(100, 99.2, 1.2)
x
x <- rnorm(1000, 99.2, 1.2)
y <- rnorm(10000, 97.3, 0.85)
z <- rnorm(10000, 98.1, 0.4)
plot(ecdf(x), col=rgb(1,0,0), main=NA)
plot(ecdf(y), col=rgb(0,1,0), add=T)
plot(ecdf(z), col=rgb(0,0,1), add=T)
legend('right', c('x', 'y', 'z'), fill=c(rgb(1,0,0), rgb(0,1,0), rgb(0,0,1)))
ncol<-5
nrow<-5
matrixA<-matrix(runif(ncol*nrow), ncol=ncol)
matrixB<-matrix(runif(ncol*nrow), ncol=ncol)
matrixA
matrixB
cosine_sim = function(matrixA, matrixB) {}
cosine_sim<-function(matrixA, matrixB){
m=tcrossprod(matrixA, matrixB)
c1=sqrt(apply(matrixA, 1, crossprod))
c2=sqrt(apply(matrixB, 1, crossprod))
m / outer(c1,c2)
}
cosine_sim(matrixA,matrixB)
library(tm)
library(tm)
data(acq)
str(acq)
tdm <- TermDocumentMatrix(acq)
Docs(tdm)
nDocs(tdm)
nTerms(tdm)
Terms(tdm)
View(tdm)
findFreqTerms(tdm, 30)
findAssocs(tdm, "stock", 0.70)
inspect(tdm)
inspect(removeSparseTerms(tdm, 0.3))
a <- "dog bunny dog cat hamster"
b <- "cat cat bunny dog hamster"
c <- "cat fish dog"
d <- "cat dog bunny hamster fish"
e <- "apple mango orange carrot"
f <- "cabbage apple dog"
g <- "orange mango cat apple"
h <- "apple apple orange"
i <- "apple orange carrot"
j <- c(a,b,c,d,e,f,g,h,i)
x <- data.frame(j)
docs <- Corpus(DataframeSource(x))
tzdm <- TermDocumentMatrix(docs)
dztm <- DocumentTermMatrix(docs)
tzdm
dztm
acq <- tm_map(acq, content_transformer(tolower))
acq <- tm_map(acq, stripWhitespace)
acq <- tm_map(acq, removeWords, stopwords("english"))
s <- "i am learning text mining. This is exciting . lot to explore Mr.
Paul."
MC_tokenizer(s)
scan_tokenizer(s)
install.packages("RWeka")library(RWeka)
install.packages("RWeka")
library(RWeka)
require(lightgbm)
data(agaricus.train, package = "lightgbm")
data(agaricus.test, package = "lightgbm")
library(Matrix)
data(agaricus.train, package = "lightgbm")
data(agaricus.test, package = "lightgbm")
str(agaricus.train)
data("iris")
str(iris)
tt = as.matrix(iris)
str(tt)
dtrain <- lgb.Dataset(agaricus.train$data, label = agaricus.train$label)
dtest <- lgb.Dataset(agaricus.test$data, label = agaricus.test$label)
nrounds <- 2
param <- list(num_leaves = 4,
learning_rate = 1,
objective = "binary")
print("Running cross validation")
lgb.cv(param,
dtrain,
nrounds,
nfold = 5,
eval = "binary_error")
print("Running cross validation, disable standard deviation display")
lgb.cv(param,
dtrain,
nrounds,
nfold = 5,
eval = "binary_error",
showsd = FALSE)
print("Running cross validation, with cutomsized loss function")
model = lgb.cv(param,
dtrain,
nrounds,
nfold = 5,
eval = "binary_error",
showsd = FALSE)
predict(model, newd)
predict(model, newdata = agaricus.test)
update.packages("xgboost")
install.packages("xgboost")
library("xgboost", lib.loc="~/R/R-3.4.0/library")
getwd()
setwd("C:/Users/Test User/Documents/Files/perf")
m
str(total_fxi_april)
cor(total_fxi_march[,c(10,19,20)])
cor(total_fxi_april[,c(10,19,20)])
cor(total_fxi_may[,c(10,19,20)])
cor(total_vhr_march[,c(10,19,20)])
cor(total_vhr_april[,c(10,19,20)])
cor(total_vhr_may[,c(10,19,20)])
getwd()
setwd("C:/Users/Test User/Documents/Files/perf")
dff2 = read.csv("new_format2.csv")
temp = dff2[,c(1,3:15)]
temp2 = aggregate(.~Employee.ID + From.my, data = temp, FUN = sum)
temp2$Employee = substr(as.character(temp2$Employee.ID), 1, 3)
str(temp2)
temp2$Employee = as.factor(temp2$Employee)
fxi_data = subset(temp2, temp2$Employee == "FXI")
str(fxi_data)
vhr_data = subset(temp2, temp2$Employee == "VHR")
str(vhr_data)
fxi = read.csv("fxi.csv")
fxi$March_2017 = as.numeric(as.character(fxi$March_2017))
fxi$April_2017 = as.numeric(as.character(fxi$April_2017))
fxi$May_2017 = as.numeric(as.character(fxi$May_2017))
final_fxi = merge(fxi_data, fxi, by = "Employee.ID", all.x = TRUE)
vhr = read.csv("vhr.csv")
str(vhr)
vhr$March_2017 = as.numeric(as.character(vhr$March_2017))
vhr$April_2017 = as.numeric(as.character(vhr$April_2017))
vhr$May_2017 = as.numeric(as.character(vhr$May_2017))
str(vhr)
str(vhr_data)
vhr_data$Employee.ID = as.factor(as.character(vhr_data$Employee.ID))
final_vhr = merge(vhr_data, vhr, by = "Employee.ID", all.x = TRUE)
str(final_vhr)
final_vhr = na.omit(final_vhr)
final_fxi$apr_mar = (final_fxi$April_2017 - final_fxi$March_2017)
final_fxi$may_apr = (final_fxi$May_2017 - final_fxi$April_2017)
final_vhr$apr_mar = (final_vhr$April_2017 - final_vhr$March_2017)
final_vhr$may_apr = (final_vhr$May_2017 - final_vhr$April_2017)
final_fxi$Employee = as.character(final_fxi$Employee)
final_vhr$Employee = as.character(final_vhr$Employee)
final_fxi_april = subset(final_fxi, final_fxi$From.my == 42017)
final_fxi_april2 <- na.omit(final_fxi_april)
fxi_model <- lm(apr_mar ~Type.of.Leave_Absent+Type.of.Leave_Casual.Leave+
Type.of.Leave_Casual.Leave.Confirmed.COE+Type.of.Leave_Earned.Leave+
Type.of.Leave_Earned.Leave.Confirmed.COE+Type.of.Leave_LWP+
Type.of.Leave_Sick.Leave+Leave.applied.for.no..of.days+
Status.of.Leave_Absent+Status.of.Leave_Approved+Status.of.Leave_Rejected,
data = final_fxi_april2)
summary(fxi_model)
pp = predict(fxi_model)
plot(final_fxi_april2$apr_mar, pp, col = "red")
total_fxi = final_fxi
total_vhr = final_vhr
total_fxi$apr_mar_sign = ifelse(total_fxi$apr_mar >= 0,1,-1 )
total_fxi$may_apr_sign = ifelse(total_fxi$may_apr >= 0,1,-1 )
total_vhr$apr_mar_sign = ifelse(total_vhr$apr_mar >= 0,1,-1 )
total_vhr$may_apr_sign = ifelse(total_vhr$may_apr >= 0,1,-1 )
total_fxi$apr_mar_sign = as.factor(total_fxi$apr_mar_sign)
total_fxi$may_apr_sign = as.factor(total_fxi$may_apr_sign)
table(total_fxi$apr_mar_sign)
table(total_fxi$may_apr_sign)
total_vhr$apr_mar_sign = as.factor(total_vhr$apr_mar_sign)
total_vhr$may_apr_sign = as.factor(total_vhr$may_apr_sign)
table(total_vhr$apr_mar_sign)
table(total_vhr$may_apr_sign)
total_fxi2 = na.omit(total_fxi)
total_vhr2 = na.omit(total_vhr)
total_fxi_march = na.omit(subset(total_fxi2, total_fxi$From.my == 32017))
total_fxi_april = na.omit(subset(total_fxi2, total_fxi$From.my == 42017))
total_fxi_may = na.omit(subset(total_fxi2, total_fxi$From.my == 52017))
total_vhr_march = na.omit(subset(total_vhr2, total_vhr$From.my == 32017))
total_vhr_april = na.omit(subset(total_vhr2, total_vhr$From.my == 42017))
total_vhr_may = na.omit(subset(total_vhr2, total_vhr$From.my == 52017))
str(total_fxi_april)
cor(total_fxi_march[,c(10,19,20)])
cor(total_fxi_april[,c(10,19,20)])
cor(total_fxi_may[,c(10,19,20)])
cor(total_vhr_march[,c(10,19,20)])
cor(total_vhr_april[,c(10,19,20)])
cor(total_vhr_may[,c(10,19,20)])
fxi_model <- lm(apr_mar ~Type.of.Leave_Absent+Type.of.Leave_Casual.Leave+
Type.of.Leave_Casual.Leave.Confirmed.COE+Type.of.Leave_Earned.Leave+
Type.of.Leave_Earned.Leave.Confirmed.COE+Type.of.Leave_LWP+
Type.of.Leave_Sick.Leave+Leave.applied.for.no..of.days+
Status.of.Leave_Absent+Status.of.Leave_Approved+Status.of.Leave_Rejected,
data = final_fxi_april2)
summary(fxi_model)
pp = predict(fxi_model)
head(pp)
head(pp, final_fxi_april2$apr_mar)
table(pp, final_fxi_april2$apr_mar)
plot(final_fxi_april2$apr_mar, pp, col = "red")
summary(final_fxi_april2$apr_mar)
